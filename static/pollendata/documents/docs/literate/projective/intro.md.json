{"attributes":{"backlinks":[{"tag":"document","title":"toc","docid":"/documents/toc.md"}],"path":"/home/lorenz/.julia/dev/DataAugmentation/docs/literate/projective/intro.md","title":"Projective transformations"},"tag":"document","children":[{"attributes":{},"tag":"h1","children":[{"mimes":{"text/plain":"Projective transformations"}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"DataAugmentation"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":"jl has great support for transforming spatial data like images and keypoints"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" Most of these transformations are projective transformations"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" For our purposes, a projection means a mapping between two coordinate spaces"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" In computer vision, these are frequently used for preprocessing and augmenting image data: images are randomly scaled, maybe flipped horizontally and finally cropped to the same size"}},{"mimes":{"text/plain":"."}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"This library generalizes projective transformations for different kinds of image and keypoint data in an N"}},{"mimes":{"text/plain":"-"}},{"mimes":{"text/plain":"dimensional Euclidean space"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" It also uses composition for performance improvements like fusing affine transformations"}},{"mimes":{"text/plain":"."}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"Unlike mathematical objects, the spatial data we want to transform has "}},{"attributes":{},"tag":"em","children":[{"mimes":{"text/plain":"spatial bounds"}}]},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" For an image, these bounds are akin to the array size"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" But keypoint data aligned with an image has the same bounds even if they are not explicitly encoded in the representation of the data"}},{"mimes":{"text/plain":"."}},{"attributes":{},"tag":"br","children":[]},{"mimes":{"text/plain":"These spatial bounds can be used to dynamically create useful transformations"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" For example, a rotation around the center or a horizontal flip of keypoint annotations can be calculated from the bounds"}},{"mimes":{"text/plain":"."}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"Often, we also want to "}},{"attributes":{},"tag":"em","children":[{"mimes":{"text/plain":"crop"}}]},{"mimes":{"text/plain":" an area from the projected results"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" By evaluating only the parts of a projection that fall inside the cropped area, a lot of unnecessary computation can be avoided"}},{"mimes":{"text/plain":"."}}]},{"attributes":{},"tag":"h2","children":[{"mimes":{"text/plain":"An example pipeline"}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"We can break down most augmentation used in practive into a single (possibly stochastic) projection and a crop"}},{"mimes":{"text/plain":"."}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"As an example, consider an image augmentation pipeline: A random horizontal flip, followed by a random resized crop"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" The latter resizes and crops (irregularly sized) images to a common size without distorting the aspect ratio"}},{"mimes":{"text/plain":"."}}]},{"attributes":{"lang":"julia"},"tag":"codeblock","children":[{"attributes":{},"tag":"CST_DEFINITION","children":[{"attributes":{},"tag":"CST_call","children":[{"attributes":{},"tag":"CST_call","children":[{"attributes":{"reftype":"symbol","document_id":"references/DataAugmentation.Maybe"},"tag":"reference","children":[{"mimes":{"text/plain":"Maybe"}}]},{"attributes":{},"tag":"CST_BRACKET","children":[{"mimes":{"text/plain":"("}}]},{"attributes":{},"tag":"CST_call","children":[{"attributes":{"reftype":"symbol","document_id":"references/DataAugmentation.FlipX"},"tag":"reference","children":[{"mimes":{"text/plain":"FlipX"}}]},{"attributes":{},"tag":"CST_BRACKET","children":[{"mimes":{"text/plain":"("}}]},{"attributes":{},"tag":"CST_BRACKET","children":[{"mimes":{"text/plain":")"}}]}]},{"attributes":{},"tag":"CST_BRACKET","children":[{"mimes":{"text/plain":") "}}]}]},{"attributes":{},"tag":"CST_OPERATOR","children":[{"mimes":{"text/plain":"|> "}}]},{"attributes":{},"tag":"CST_call","children":[{"attributes":{"reftype":"symbol","document_id":"references/DataAugmentation.RandomResizeCrop"},"tag":"reference","children":[{"mimes":{"text/plain":"RandomResizeCrop"}}]},{"attributes":{},"tag":"CST_BRACKET","children":[{"mimes":{"text/plain":"("}}]},{"attributes":{},"tag":"CST_tuple","children":[{"attributes":{},"tag":"CST_BRACKET","children":[{"mimes":{"text/plain":"("}}]},{"attributes":{},"tag":"CST_IDENTIFIER","children":[{"mimes":{"text/plain":"h"}}]},{"attributes":{},"tag":"CST_PUNCTUATION","children":[{"mimes":{"text/plain":", "}}]},{"attributes":{},"tag":"CST_IDENTIFIER","children":[{"mimes":{"text/plain":"w"}}]},{"attributes":{},"tag":"CST_BRACKET","children":[{"mimes":{"text/plain":")"}}]}]},{"attributes":{},"tag":"CST_BRACKET","children":[{"mimes":{"text/plain":")"}}]}]}]}]}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"Let"}},{"mimes":{"text/plain":"’"}},{"mimes":{"text/plain":"s pull apart the steps involved"}},{"mimes":{"text/plain":"."}}]},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"Half of the time, flip the image horizontally"}},{"mimes":{"text/plain":"."}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"Scale the image down without distortion so that the shorter side length is 128"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" With an input of size "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"(512, 256)"}}]},{"mimes":{"text/plain":" this result in scaling both dimensions by "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"1/2"}}]},{"mimes":{"text/plain":", resulting in an image with side lengths "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"(256, 128)"}}]},{"mimes":{"text/plain":"."}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"Crop a random "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"(128, 128)"}}]},{"mimes":{"text/plain":" portion from that image"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" There is only "}},{"mimes":{"text/plain":"“"}},{"mimes":{"text/plain":"wiggle room"}},{"mimes":{"text/plain":"”"}},{"mimes":{"text/plain":" on the y"}},{"mimes":{"text/plain":"-"}},{"mimes":{"text/plain":"axis (which, by convention, is the first)"}},{"mimes":{"text/plain":"."}}]}]}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"All of these steps can be efficiently computed in one step with two tricks:"}}]},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"Some projections like reflection, translation, scaling and rotation can be composed into a single projection matrix"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" This means in the above example we only need to apply one projection which represents both the flipping (a reflection) and the scaling"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" Especially in pipelines with many augmentation steps this avoids a lot of unnecessary computation"}},{"mimes":{"text/plain":"."}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"In cases, where the result of the projection is cropped, we can save additional computing by only evaluating the parts that we want to keep"}},{"mimes":{"text/plain":"."}}]}]}]},{"attributes":{},"tag":"h2","children":[{"mimes":{"text/plain":"Cropping"}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"By default, the bounds of a projected item will be chosen so they still encase all the data"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" So after applying a "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"Scale((2, 2))"}}]},{"mimes":{"text/plain":" to an "}},{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"Image"}}]},{"mimes":{"text/plain":", its bounds will also be scaled by 2"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" Sometimes, however, we want to crop a part of the projected output, for example so a number of images can later be batched into a single array"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" While the crop usually has a fixed size, the region to crop still needs to be chosen"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" For validation data (which should be transformed deterministically), a center crop is usually used"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" For training data, on the other hand, a random region is selected to add additional augmentation"}},{"mimes":{"text/plain":"."}}]},{"attributes":{},"tag":"hr","children":[]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"Read on to find out "}},{"attributes":{"reftype":"document","href":"./interface.md","title":"","document_id":"documents/docs/literate/projective/interface.md"},"tag":"reference","children":[{"mimes":{"text/plain":"how projective transformations are implemented"}}]},{"mimes":{"text/plain":" or jump straight to the "}},{"attributes":{"reftype":"document","href":"./usage.md","title":"","document_id":"documents/docs/literate/projective/usage.md"},"tag":"reference","children":[{"mimes":{"text/plain":"usage section"}}]},{"mimes":{"text/plain":"."}}]}]}