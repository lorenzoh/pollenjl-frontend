{"attributes":{"path":"/home/lorenz/.julia/dev/DataLoaders/docs/motivation.md"},"tag":"document","children":[{"attributes":{},"tag":"h2","children":[{"mimes":{"text/plain":"Motivation"}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"Training deep learning models, data loading can quickly become a bottleneck"}},{"mimes":{"text/plain":"."}},{"mimes":{"text/plain":" When we cannot preload the dataset into memory, we have to load and preprocess it batch by batch during training"}},{"mimes":{"text/plain":"."}}]},{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"To not slow down the training, loading a batch must"}}]},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"not take longer than one training step"}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"not block the main thread; and"}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"avoid garbage collection pauses"}}]}]}]},{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":[{"mimes":{"text/plain":"DataLoaders"}}]}]},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"uses multiple worker threads to maximize throughput"}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"keeps the main thread free for the training step; and"}}]}]},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"mimes":{"text/plain":"allows buffered data loading for supporting data containers to reduce allocations"}}]}]}]}]}